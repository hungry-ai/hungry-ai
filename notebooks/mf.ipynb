{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e515e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a4ebb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg\n",
    "import time\n",
    "\n",
    "from src.graph import visualize\n",
    "from src.recommender import train_mf, reviews_dataset, evaluate_recommendations\n",
    "from src.tags import PytorchWordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98d50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, reviews_validation, reviews_test, images = reviews_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab37681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "splidd_regex = re.compile(\",|&|/\")\n",
    "replace_regex = re.compile(\" |\\(|\\)|\\'|-\")\n",
    "\n",
    "def parse_tags(tags_raw):\n",
    "    if not isinstance(tags_raw, str):\n",
    "        return []\n",
    "    \n",
    "    tags = []\n",
    "    for tag_raw in re.split(splidd_regex, tags_raw):\n",
    "        tag = re.sub(replace_regex, \"\", tag_raw.strip().lower())\n",
    "        if tag:\n",
    "            tags.append(tag)\n",
    "    return tags\n",
    "\n",
    "images[\"tags_parsed\"] = images[\"tags\"].apply(parse_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d010ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = reviews_train.copy()\n",
    "\n",
    "user_ids = train_data['user_id'].drop_duplicates()\n",
    "user_indices = user_ids.reset_index(drop=True).reset_index()\n",
    "user_indices = user_indices.rename(columns={\"index\": \"user_index\"})\n",
    "train_data = train_data.merge(user_indices, on=\"user_id\")\n",
    "n = len(user_indices)\n",
    "\n",
    "image_ids = train_data[\"image_id\"].drop_duplicates()\n",
    "image_indices = image_ids.reset_index(drop=True).reset_index()\n",
    "image_indices = image_indices.rename(columns={\"index\": \"image_index\"})\n",
    "train_data = train_data.merge(image_indices, on=\"image_id\")\n",
    "m = len(image_indices)\n",
    "\n",
    "all_tags = images[\"tags_parsed\"].explode().dropna().unique()\n",
    "tag_indices = {tag: tag_index for tag_index, tag in enumerate(all_tags)}\n",
    "k = len(all_tags)\n",
    "\n",
    "def tag_vector(tags):\n",
    "    if not tags:\n",
    "        return np.zeros((1, k))\n",
    "    return (sum([np.eye(1, k, tag_indices[tag]) for tag in tags])) / len(tags)\n",
    "\n",
    "image_tags_df = image_indices.merge(images[[\"image_id\", \"tags_parsed\"]], on=\"image_id\", how=\"left\")\n",
    "np.testing.assert_array_equal(image_tags_df[\"image_index\"], np.arange(m))\n",
    "image_tags = np.concatenate(image_tags_df.tags_parsed.apply(tag_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb85fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: handle duplicate reviews\n",
    "\n",
    "reviews_by_user = train_data.groupby(\"user_index\").apply(lambda group: (group[\"image_index\"].to_numpy(), group[\"rating\"].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c246833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 users processed, elapsed: 8.58s, average: 8.58s\n",
      "20000 users processed, elapsed: 14.47s, average: 7.23s\n",
      "30000 users processed, elapsed: 19.01s, average: 6.34s\n",
      "40000 users processed, elapsed: 22.72s, average: 5.68s\n",
      "50000 users processed, elapsed: 25.85s, average: 5.17s\n",
      "60000 users processed, elapsed: 29.56s, average: 4.93s\n",
      "70000 users processed, elapsed: 32.89s, average: 4.70s\n",
      "80000 users processed, elapsed: 35.89s, average: 4.49s\n",
      "90000 users processed, elapsed: 38.51s, average: 4.28s\n",
      "100000 users processed, elapsed: 41.09s, average: 4.11s\n",
      "110000 users processed, elapsed: 43.56s, average: 3.96s\n",
      "120000 users processed, elapsed: 45.83s, average: 3.82s\n",
      "130000 users processed, elapsed: 48.10s, average: 3.70s\n",
      "140000 users processed, elapsed: 50.23s, average: 3.59s\n",
      "150000 users processed, elapsed: 52.28s, average: 3.49s\n",
      "160000 users processed, elapsed: 54.38s, average: 3.40s\n",
      "170000 users processed, elapsed: 56.68s, average: 3.33s\n",
      "180000 users processed, elapsed: 58.62s, average: 3.26s\n",
      "190000 users processed, elapsed: 60.37s, average: 3.18s\n",
      "200000 users processed, elapsed: 62.18s, average: 3.11s\n",
      "210000 users processed, elapsed: 63.87s, average: 3.04s\n",
      "220000 users processed, elapsed: 65.36s, average: 2.97s\n",
      "230000 users processed, elapsed: 66.72s, average: 2.90s\n",
      "240000 users processed, elapsed: 68.16s, average: 2.84s\n",
      "250000 users processed, elapsed: 69.45s, average: 2.78s\n",
      "260000 users processed, elapsed: 70.75s, average: 2.72s\n",
      "270000 users processed, elapsed: 71.99s, average: 2.67s\n",
      "280000 users processed, elapsed: 73.27s, average: 2.62s\n",
      "290000 users processed, elapsed: 74.48s, average: 2.57s\n",
      "300000 users processed, elapsed: 75.65s, average: 2.52s\n",
      "310000 users processed, elapsed: 76.81s, average: 2.48s\n",
      "320000 users processed, elapsed: 77.93s, average: 2.44s\n",
      "330000 users processed, elapsed: 79.06s, average: 2.40s\n",
      "340000 users processed, elapsed: 80.21s, average: 2.36s\n",
      "350000 users processed, elapsed: 81.29s, average: 2.32s\n",
      "360000 users processed, elapsed: 82.36s, average: 2.29s\n",
      "370000 users processed, elapsed: 83.47s, average: 2.26s\n",
      "380000 users processed, elapsed: 84.55s, average: 2.22s\n",
      "390000 users processed, elapsed: 85.61s, average: 2.20s\n",
      "400000 users processed, elapsed: 86.66s, average: 2.17s\n",
      "410000 users processed, elapsed: 87.70s, average: 2.14s\n",
      "420000 users processed, elapsed: 88.69s, average: 2.11s\n",
      "430000 users processed, elapsed: 89.67s, average: 2.09s\n",
      "440000 users processed, elapsed: 90.62s, average: 2.06s\n",
      "450000 users processed, elapsed: 91.62s, average: 2.04s\n",
      "460000 users processed, elapsed: 92.57s, average: 2.01s\n",
      "470000 users processed, elapsed: 93.55s, average: 1.99s\n",
      "480000 users processed, elapsed: 94.48s, average: 1.97s\n",
      "490000 users processed, elapsed: 95.42s, average: 1.95s\n",
      "500000 users processed, elapsed: 96.33s, average: 1.93s\n",
      "510000 users processed, elapsed: 97.25s, average: 1.91s\n",
      "520000 users processed, elapsed: 98.15s, average: 1.89s\n",
      "530000 users processed, elapsed: 99.02s, average: 1.87s\n",
      "540000 users processed, elapsed: 99.90s, average: 1.85s\n",
      "550000 users processed, elapsed: 100.77s, average: 1.83s\n",
      "560000 users processed, elapsed: 101.63s, average: 1.81s\n",
      "570000 users processed, elapsed: 102.46s, average: 1.80s\n",
      "580000 users processed, elapsed: 103.31s, average: 1.78s\n",
      "590000 users processed, elapsed: 104.13s, average: 1.76s\n",
      "600000 users processed, elapsed: 105.04s, average: 1.75s\n",
      "610000 users processed, elapsed: 105.87s, average: 1.74s\n",
      "620000 users processed, elapsed: 106.71s, average: 1.72s\n",
      "630000 users processed, elapsed: 107.49s, average: 1.71s\n",
      "640000 users processed, elapsed: 108.32s, average: 1.69s\n",
      "650000 users processed, elapsed: 109.13s, average: 1.68s\n",
      "660000 users processed, elapsed: 109.94s, average: 1.67s\n",
      "670000 users processed, elapsed: 110.70s, average: 1.65s\n",
      "680000 users processed, elapsed: 111.47s, average: 1.64s\n",
      "690000 users processed, elapsed: 112.28s, average: 1.63s\n",
      "700000 users processed, elapsed: 113.10s, average: 1.62s\n",
      "710000 users processed, elapsed: 114.00s, average: 1.61s\n",
      "720000 users processed, elapsed: 115.14s, average: 1.60s\n",
      "730000 users processed, elapsed: 116.01s, average: 1.59s\n",
      "740000 users processed, elapsed: 116.84s, average: 1.58s\n",
      "750000 users processed, elapsed: 117.65s, average: 1.57s\n",
      "760000 users processed, elapsed: 118.46s, average: 1.56s\n",
      "770000 users processed, elapsed: 119.19s, average: 1.55s\n",
      "780000 users processed, elapsed: 119.89s, average: 1.54s\n",
      "790000 users processed, elapsed: 120.64s, average: 1.53s\n",
      "800000 users processed, elapsed: 121.38s, average: 1.52s\n",
      "810000 users processed, elapsed: 122.09s, average: 1.51s\n",
      "820000 users processed, elapsed: 122.82s, average: 1.50s\n",
      "830000 users processed, elapsed: 123.60s, average: 1.49s\n",
      "840000 users processed, elapsed: 124.33s, average: 1.48s\n",
      "850000 users processed, elapsed: 125.10s, average: 1.47s\n",
      "860000 users processed, elapsed: 125.83s, average: 1.46s\n",
      "870000 users processed, elapsed: 126.57s, average: 1.45s\n",
      "880000 users processed, elapsed: 127.30s, average: 1.45s\n",
      "890000 users processed, elapsed: 128.01s, average: 1.44s\n",
      "900000 users processed, elapsed: 128.66s, average: 1.43s\n",
      "910000 users processed, elapsed: 129.35s, average: 1.42s\n",
      "920000 users processed, elapsed: 130.01s, average: 1.41s\n",
      "930000 users processed, elapsed: 130.66s, average: 1.40s\n",
      "940000 users processed, elapsed: 131.30s, average: 1.40s\n",
      "950000 users processed, elapsed: 131.99s, average: 1.39s\n",
      "960000 users processed, elapsed: 132.65s, average: 1.38s\n",
      "970000 users processed, elapsed: 133.38s, average: 1.38s\n",
      "980000 users processed, elapsed: 134.02s, average: 1.37s\n",
      "990000 users processed, elapsed: 135.02s, average: 1.36s\n",
      "1000000 users processed, elapsed: 135.76s, average: 1.36s\n",
      "1010000 users processed, elapsed: 136.45s, average: 1.35s\n",
      "1020000 users processed, elapsed: 137.10s, average: 1.34s\n",
      "1030000 users processed, elapsed: 137.76s, average: 1.34s\n",
      "1040000 users processed, elapsed: 138.40s, average: 1.33s\n",
      "1050000 users processed, elapsed: 139.02s, average: 1.32s\n",
      "1060000 users processed, elapsed: 139.65s, average: 1.32s\n",
      "1070000 users processed, elapsed: 140.31s, average: 1.31s\n"
     ]
    }
   ],
   "source": [
    "# R = X Y^T I^T : R (nxm), X (nxd), Y (kxd), I (mxk)\n",
    "\n",
    "d = 20\n",
    "alpha = .01\n",
    "beta = .01\n",
    "als_epochs = 10\n",
    "learning_rate = .1\n",
    "sgd_epochs = 10\n",
    "\n",
    "X = np.random.normal(size=(n, d))\n",
    "Y = np.random.normal(size=(k, d))\n",
    "\n",
    "def gradient(i):\n",
    "    grad = 2 * beta/(k * d) * Y[i]\n",
    "    start = time.time()\n",
    "    for u, (image_ids, ratings) in reviews_by_user.items():\n",
    "        if u % 10000 == 0 and u > 0:\n",
    "            end = time.time()\n",
    "            print(f\"{u} users processed, elapsed: {end - start:.2f}s, average: {(end - start) * 10000 / u:.2f}s\")\n",
    "        io = image_tags[image_ids]\n",
    "        grad += (2/nnz) * (io[:,i] @ (io @ (Y @ X[u]) - ratings)) * X[u]\n",
    "    return grad\n",
    "\n",
    "def tiny_gradient(i, sample_size=1):\n",
    "    sample = reviews_by_user.sample(sample_size)\n",
    "    grad = 2 * beta / (k * d) * Y[i]\n",
    "    for u, (image_ids, ratings) in sample.items():\n",
    "        io = image_tags[image_ids]\n",
    "        grad += 2 / (sample_size * len(image_ids)) * (io[:,i] @ (io @ (Y @ X[u]) - ratings)) * X[u]\n",
    "    return grad\n",
    "\n",
    "for als_epoch in range(als_epochs):\n",
    "    # X = argmin ||(R - X Y^T I^T)_observed||_F^2 + alpha ||X||_F^2\n",
    "    # Y^t I^t diag(O_u)^t diag(O_u) r_u = (Y^t I^t diag(O_u)^t diag(O_u) I Y + alpha I_{d x d}) x_u\n",
    "    start = time.time()\n",
    "    for u, (image_ids, ratings) in reviews_by_user.items():\n",
    "        if u % 10000 == 0 and u > 0:\n",
    "            end = time.time()\n",
    "            print(f\"{u} users processed, elapsed: {end - start:.2f}s, average: {(end - start) * 10000 / u:.2f}s\")\n",
    "        \n",
    "        A = alpha/(n*d) * np.eye(d)\n",
    "        b = np.zeros(d)\n",
    "        for i, r in zip(image_ids, ratings):\n",
    "            a = image_tags[i] @ Y\n",
    "            b += r * a\n",
    "            a = a.reshape(1, -1)\n",
    "            A += a.T @ a\n",
    "        \n",
    "        X[u] = np.linalg.solve(A, b)\n",
    "    \n",
    "    # Y = argmin ||(R - X Y^T I^T)_observed||_F^2 + beta ||Y||_F^2\n",
    "    # beta Y + sum_{r_{ui}} i_i i_i^T Y x_u x_u^T = sum_{r_{ui}} r_{ui} i_i x_u^T\n",
    "    start = time.time()\n",
    "    for sgd_epoch in range(sgd_epochs):\n",
    "        print(f\"{sgd_epoch=}\")\n",
    "        for i in range(k):\n",
    "            if i % 50 == 0:\n",
    "                print(i)\n",
    "            Y[i] -= learning_rate / (sgd_epoch + 1) * tiny_gradient(i, sample_size=10)\n",
    "        \n",
    "        loss = 1/n * sum(1 / len(image_ids) * sum((ratings - image_tags[image_ids] @ (Y @ X[u])) ** 2) for u, (image_ids, ratings) in reviews_by_user.items() if len(image_ids) > 0) + beta / (k * d) * np.linalg.norm(Y) ** 2\n",
    "        print(f\"{loss=}\")\n",
    "        \n",
    "        end = time.time()\n",
    "        print(f\"{end-start:.2f}s elapsed, {(end-start)/(sgd_epoch+1):.2f}s average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90539671",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = train_knn(reviews_train, word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(recommender.graph, {vertex: vertex.id for vertex in recommender.graph.vertices})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c9c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_recommendations(recommender, reviews_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f69885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f27786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
